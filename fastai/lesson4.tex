% -*- coding:utf-8 -*-
% LATEX PREAMBLE --- needs to be imported manually
\documentclass[12pt]{article}
% \special{papersize=3in,5in}

\usepackage[utf8]{inputenc}
\usepackage{amssymb,amsmath}
\pagestyle{empty}
\setlength{\parindent}{0in}

\input ../texpad_macros.tex

\begin{document}

Dropout: During training, per minibatch, in some layer, delete some fraction of the activations (i.e. make them 0). This helps with generalization.

*** Average activations?

*** Dropout on conv layers or fully connected / linear layers?

*** Linear and fully connected are the same thing?

\end{document}