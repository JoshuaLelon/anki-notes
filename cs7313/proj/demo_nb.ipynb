{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\joshu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from main import train_nb, evaluate_nb\n",
    "\n",
    "# train(model, dataset, gpu, freeze_base, max_len, batch_size, learning_rate, print_per_n_lines, max_epochs)\n",
    "# evaluate(model, dataset, gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a Naive Bayes classifier on  twitter\n",
      "Tokenizing took 1.963768720626831 seconds\n",
      "Starting token dictionary creation of  9233  entries.\n",
      "Creating a token dictionary took 236.6512327194214 seconds\n",
      "Training took 1.259638786315918 seconds\n"
     ]
    }
   ],
   "source": [
    "classifier, all_words = train_nb(\"twitter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating a Naive Bayes classifier on  twitter\n",
      "Tokenizing took 222.19287252426147 seconds\n",
      "Classification took 2.7685956954956055 seconds\n",
      "Accuracy:  0.64\n"
     ]
    }
   ],
   "source": [
    "evaluate_nb(\"twitter\", classifier, all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a Naive Bayes classifier on  imdb\n",
      "Tokenizing took 26.08325695991516 seconds\n",
      "Starting token dictionary creation of  20000  entries.\n",
      "Creating a token dictionary took 12549.881498336792 seconds\n",
      "Training took 10.389251232147217 seconds\n"
     ]
    }
   ],
   "source": [
    "classifier, all_words = train_nb(\"imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating a Naive Bayes classifier on  imdb\n",
      "Tokenizing took 10983.46337389946 seconds\n",
      "Classification took 25.9775607585907 seconds\n",
      "Accuracy:  0.64\n"
     ]
    }
   ],
   "source": [
    "evaluate_nb(\"imdb\", classifier, all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a Naive Bayes classifier on  amazon\n",
      "Tokenizing took 216.10335063934326 seconds\n",
      "Starting token dictionary creation of  228384  entries.\n",
      "Creating a token dictionary took 22509.381916046143 seconds\n",
      "Training took 48.70878076553345 seconds\n"
     ]
    }
   ],
   "source": [
    "classifier, all_words = train_nb(\"amazon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating a Naive Bayes classifier on  amazon\n"
     ]
    }
   ],
   "source": [
    "evaluate_nb(\"amazon\", classifier, all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
